\chapter{Workflows - Development processes} \label{ch:workflow}

This chapter is concerned with the process of several procedures repeatedly used while developing spoken dialogue system providing public transport information in New York (\ac{PTINY} ).
Very similar approaches might be taken for the development of dialogue systems in different domains.

\section{Creating CrowdFlower Job}

Assembling a CrowdFlower job can be realized through one of many templates for ordinary tasks such as various data analysis, entity annotation, categorization, comparison, revision and many more.%, review, transcription %etc. %executed, accomplished
Custom and more sophisticated tasks can be carried out from scratch.
It is desirable that the tasks are as simple as possible to eliminate errors resulting from the lack of knowledge or misinterpretation.

%The platform automatically inserts test question and evaluates contributors based on them.
CrowdFlower provides a web interface for work requesters to edit the task by \acf{CML}, CSS and custom JavaScript that runs once on page load.
There is a possibility to inject custom HTML code as well.
CML and JavaScript are essential for leveraging Crowdflower's quality control.
Both mandatory and optional input controls have to be specified with the \ac{CML}.

\subsection{Call job}

We created a call job for testing operational dialogue system.
Its purpose is to encourage solvers to call on a toll-free number and ask questions about the public transport in New York and to evaluate and rate the system.

To ensure the call is carried out thoroughly by the contributor, we employed a simple generator of four digit codes.
A code is handed out by the dialogue system after finishing a call.
It is spelled number after number three times over.
In the same time, the code is registered at a validation server running on a dedicated MetaCentrum \ac{VM}.
Without this code it is not possible to submit a feedback form and finish the job.

This behavior of the CrowdFlower job is enforced by a \ac{CML} control with a custom JavaScript validator.
When contributor inserts a code to the \ac{CML} control, the validator sends a request with the code to the validation server.
Server compares the code with a set of registered codes from the dialogue system.
Only after receiving positive server response the validator passes.
It is unnecessary to match callers identity, this is sufficient measure for enforcing the call.
%The request needs to be sent over HTTPS, otherwise CrowdFlower will terminate it.
\ask{should we introduce a figure of the validation process to destroy the block of text? or a figure of the feedback form or CF pages?}

To further maximize the efficiency, we imposed a rule for the code giveaway.
The dialogue system only hands out the validation code after minimum number of turns has passed.
This prevents the callers from saying \textit{``Hello, Good bye!''} and collecting the validation code and therefore the reward without fulfilling the task.

The job web page was built as a survey job from scratch.
In the premise of the job, we declare four paragraphs concerning the job.

\begin{itemize}
	\item \textbf{Intro} - Introduction to the whole process, mentioning restrictions and remarks. %requirements. environment, native speaker
	\item \textbf{Instructions} - Exact procedure description,  how to behave, how to end the call, how to fill the feedback form.
	%exact description of the call procedure and system capabilities
	\item \textbf{Example call} - Demonstrative dialogue between caller and our dialogue system.
	\item \textbf{Consent} - Legal statement concerning the data management and recording the call.
\end{itemize}

%From the example call solvers could pick up how to ask if they were helpless

Stops between which caller wants to find a connection are quoted after the premise.
Additional question about the link are urged for exploiting the dialogue system features.

A feedback form of subjective user satisfaction concludes the job page.
In addition to the mandatory questions an optional field for general comments and field for the validation code are within the form.

A toll-free number provided by the department was used for this job.
CrowdFlower allows to geographically limit work force only to United States.
The number of calls per job was temporarily set to one to ensure the diversity of callers.
Four \acp{VM} on MetaCentrum were dedicated to this job to serve multiple callers.

\subsection{Transcription job}

After collecting enough calls a transcription job was built from a template for audio transcriptions.
For each audio track there is a radio button for marking comprehensible tracks and a field for writing transcribed text.
Only instructions and data are needed for launching a transcription job.

This kind of job is very common and popular and therefore it is solved by contributors very quickly.
However, the contributors differ on spelling of some words and it is absolutely crucial for the job instructions to make it perfectly clear how should the contributor write.
%The phone quality of the audio is not helping.
%in the sense of colloquial speech

Data are uploaded to CrowdFlower via \acf{CSV} file that contains a list of URLs with audio tracks.
The default setup suggests to let each track transcribe three times for accuracy.
Even more transcriptions yield from setting up dynamic judgments.
However, repeated labeling is costly and may tend to move towards the in-house solution in that regard. %aspect
We decided to keep multiple transcriptions while reducing costs per transcription.
The ultimate transcription is decided upon later from the job results by a custom semi-automatic Python script.

CrowdFlower uses test questions for separating the good transcribers from the bad.
Test questions in this job are essentially manual transcriptions.
We utilized a quiz mode that estimates the quality of a contributor beforehand.
It is assembled from test questions and lets only trusted contributors to participate in the job.
%CrowdFlower offers the option of screening users via quiz that takes place beforehand to determine quality of the worker.

In the instructions we defined examples of how common words should be handled.
Also a table with symbols for incomprehensible tracks was specified.
It is a good practice to let the users know the context.
The contributors were more content when a list of phrases they might hear was included.% even though the test questions were strict.
In our case the list included phrases like \textit{number of transfers}, \textit{duration of the trip}, \textit{weather forecast}, origin and destination stops etc.
Even though some of those phrases did not appear in the exact form in the audio tracks, the evidence of improvement was observable in contributor satisfaction stats of the job within CrowdFlower.
%fairness of the test question increased in their opinion

\section{Iterative improvement}

At the beginning we had just a vague idea about how the system should behave.
We had a general insight of the features from the Czech dialogue system, however we did not know what is the native way of asking for information. %It was not clear how they will ask.
Therefore we made a bootstrap list of sentences with their semantic complements, all of which our dialogue system must work on.

When an operational dialogue system was achieved, we employed CrowdFlower workforce for obtaining feedback from real users.
Analyzing logs was very important for discovering ways of inquiring information which we initially did not think of.
The log analysis and feedback form from CrowdFlower jobs also provided an input on what features are missing or need improvement.
The iterative process of improvement is captured in essence by the following steps. %nutshell, rundown, synopsis, digest

\begin{enumerate}
	\item Launch a CrowdFlower call job
	\item Obtain logs from \acp{VM}
	\item Fix flaws in:
	\begin{itemize}
		\item \textbf{\ac{SLU}} - enrich bootstrap from user turns and maintain 100\% precision
		\item \textbf{\ac{DM}} - amend features of the dialogue system
		\item \textbf{\ac{NLG}} - add templates from system turns to polish rough expressions
	\end{itemize}
	\item Upload source code to \acp{VM}
	\item Restart the dialogue systems.
\end{enumerate}

%This rundown may be executed multiple times per job
%logs render a room for improvement.

The dialogue system on each \ac{VM} is running in a docker container.
Any folder can be mounted to the docker container via \texttt{-v} flag.
Uploading source code to update dialogue system on \ac{VM} is therefore effortless and makes the development loop very quick.


\section{Building Kaldi \acs{ASR}}

For building Kaldi decoder we used Pykaldi\footnote{\url{https://github.com/UFAL-DSG/pykaldi}} docker image containing the essential tools.
It is necessary to add dependencies for \ac{ASDF} if building and evaluation is intended within the platform.
\ac{SRILM}\footnote{\url{http://www.speech.sri.com/projects/srilm/}} must be installed for training \acf{LM}.

%\subsubsection{Language model}

Prior to training \ac{LM}, it is necessary to dump database for creating a labeled list of database entries. % surface forms.
It is used for balancing probabilities of every database entry within its class in the \ac{LM}.
Finally, we need to define domain specific corpus for training the \ac{LM} .
Our training data consist of utterances from CrowdFlower call logs, bootstrap utterances and utterances generated by grammar.

\subsubsection{Context-free grammar}

Creating a good \ac{LM} entails a good probability distribution of words in the corpus.
This can be achieved naturally by collecting a lot of transcriptions.
As we do not posses large number of transcriptions, we decided to bootstrap \ac{LM} with generating utterances by grammar.
It should produce utterances that are most likely to be used and therefore it should cover the most frequent cases. %situations

Our context-free grammar is written in Python and it can be assembled from the following prescriptions for simple rewriting rules.

\begin{itemize}
	\item \textbf{Alternative} -- exactly one of many
		%\begin{fleqn}[15pt]
		\begin{flalign*}
			A^{i}(x_{1}, x_{2},...,x_{n}) \text{ adds } & A^{i}\rightarrow x_{1} & \\
			& A^{i}\rightarrow x_{2} & \\
			& \vdots & \\
			& A^{i}\rightarrow x_{n} &
			%n \in \mathbb{N}, x_{1}, x_{2},\hdots x_{n} \in V_{T}, A \in V_{N}
		\end{flalign*}
		%\end{fleqn}
	\item \textbf{Option} -- either present or not
		%\begin{fleqn}[15pt]
		\begin{flalign*}
			O^{i}(x) \text{ adds } & O^{i}\rightarrow x & \\
			& O^{i}\rightarrow \lambda &
			%x, \lambda \in V_{T}, O \in V_{N}
		\end{flalign*}
		%\end{fleqn}
	\item \textbf{Sequence} -- chain of rules
		%\begin{fleqn}[15pt]
		\begin{flalign*}
			& S^{i}(x_{1}, x_{2},\hdots,x_{n}) \text{ adds } S^{i}\rightarrow x_{1}\,x_{2}\,\hdots\,x_{n} & 
			%n \in \mathbb{N}, x_{1}, x_{2},\hdots x_{n} \in V_{T}, S \in V_{N}
		\end{flalign*}
		%\end{fleqn}
\end{itemize}

\noindent where for the $i$-th rewriting rule:

\begin{flalign*}
	& \left \{ A^{i}, O^{i}, S^{i} \right \} \subseteq  V_{N} \hdots \text{nonterminals} \\
	& x, x_{1}, x_{2},\hdots x_{n}, \lambda \in V_{T} \hdots \text{terminals} \\
	& n \in \mathbb{N}
\end{flalign*}

Explicit grammar can be assembled using these prescriptions which can than simply generate random utterances in desired number.
An example of plain grammar can be built as follows.
 
\lstset{language=Python,basicstyle=\footnotesize,showstringspaces=false,morekeywords={period, pref_p, pref_q, subj, weather}}
\begin{lstlisting}[frame=single]
pref_p = A('can you tell me', 'i would like to know')
pref_q = A('what is', 'what will be')
subj = A('weather', 'forecast', 'weather forecast')
period = A('for tomorrow', 'in the afternoon')
weather = S(O(pref_p), O(pref_q), 'the', subj, O(period))
\end{lstlisting}

The nonterminal \texttt{weather} yields utterances asking about the weather.
Terminals can be also loaded from file, which is useful for defining alternatives for waypoints for example.

The final grammar should cover as many utterances as possible.
However, it is easy to include utterances that are not used in conversation or does not make sense at all.
From the example above a sentence \textit{can you tell me the weather tomorrow} is not exactly what we wanted to include.
Even though it is syntactically correct, it is not something to be used in \ac{PTI} domain.
This is undesirable to have in our corpus.

\todo{not so bulletproof example, i want to generate some nonsense, but not too much for illustrating my point about over-generalizing}

In addition to these rules, we have added a possibility to add explicit probability with which the rule should be selected in the alternative rule.

\begin{flushleft}
\texttt{subj = A('weather', ('forecast', 0.2), ('weather forecast', 0.2))}
\end{flushleft}

\noindent In this example the \textit{``forecast''} and \textit{``weather forecast''} will be selected with the probability of $0.2$ and the probability of \textit{``weather''} will be the complement probability -- $0.6$.
This allows us to sample from more complicated subtrees with higher probability.

\subsection{Building a decoder}

When \ac{LM} is ready, Kaldi decoder can be built.
An acoustic model is needed, in our case it is downloaded from the department server.

After running build script, it can be also tested within the \ac{ASDF}.
Statistics are computed from a test set that was created earlier from call logs when \ac{LM} was built.
The test set can be also tested with the Google \ac{ASR} which renders a good comparison between the two recognizers.

We occasionally used CloudASR\footnote{\url{https://github.com/UFAL-DSG/cloud-asr}} for manual testing.
With CloudASR, it is very easy to deploy Kaldi \ac{ASR}.
It is accessible through web interface by anyone who wants to try the decoder out by his own voice.
